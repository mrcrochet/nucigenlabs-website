# üèóÔ∏è Architecture Pipeline de Donn√©es et Recommandations - Nucigen Labs

## üìã Vue d'ensemble

Cette architecture d√©crit comment d√©velopper la pipeline pour :
1. **Collecter** les √©v√©nements (g√©opolitiques, industriels, supply chain, etc.)
2. **Traiter** et **analyser** ces √©v√©nements
3. **G√©n√©rer** des recommandations personnalis√©es par domaine/utilisateur
4. **Distribuer** les insights aux utilisateurs

---

## üéØ Objectifs

- **Personnalisation** : Recommandations bas√©es sur `sector`, `professional_role`, `intended_use`, `exposure`
- **Temps r√©el** : Mise √† jour continue des √©v√©nements et pr√©dictions
- **Scalabilit√©** : Architecture qui peut g√©rer des millions d'√©v√©nements
- **Intelligence** : Analyse causale et pr√©dictions de second ordre

---

## üèõÔ∏è Architecture en 3 Couches

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COUCHE 1: COLLECTE                        ‚îÇ
‚îÇ  Sources ‚Üí APIs ‚Üí Web Scraping ‚Üí RSS Feeds ‚Üí Manual Input   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 COUCHE 2: TRAITEMENT & ANALYSE               ‚îÇ
‚îÇ  Normalisation ‚Üí Enrichissement ‚Üí Classification ‚Üí ML/AI    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE 3: RECOMMANDATIONS & DISTRIBUTION       ‚îÇ
‚îÇ  Matching Utilisateur ‚Üí Scoring ‚Üí Filtrage ‚Üí Notification  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Couche 1 : Collecte de Donn√©es

### Sources de donn√©es

#### 1. **APIs Tierces**
```typescript
// Exemples de sources
- NewsAPI (actualit√©s g√©n√©rales)
- Alpha Vantage (donn√©es financi√®res)
- FRED API (donn√©es √©conomiques US)
- World Bank API (donn√©es macro)
- UN Comtrade (commerce international)
- IEA (√©nergie)
```

#### 2. **Web Scraping** (avec respect des ToS)
```typescript
// Sources cibl√©es
- Reuters, Bloomberg, Financial Times
- Sites gouvernementaux (sanctions, r√©gulations)
- Organisations internationales (WTO, IMF, etc.)
```

#### 3. **RSS Feeds & Webhooks**
```typescript
// Flux structur√©s
- RSS feeds de sources fiables
- Webhooks depuis services partenaires
- APIs de m√©dias sp√©cialis√©s
```

### Structure de donn√©es collect√©es

```sql
-- Table: events (√©v√©nements bruts)
CREATE TABLE events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source TEXT NOT NULL, -- 'newsapi', 'scraper', 'manual', etc.
  source_id TEXT, -- ID dans la source originale
  title TEXT NOT NULL,
  description TEXT,
  content TEXT, -- Contenu complet
  published_at TIMESTAMP WITH TIME ZONE NOT NULL,
  collected_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- M√©tadonn√©es
  url TEXT,
  author TEXT,
  language TEXT DEFAULT 'en',
  
  -- Classification initiale (peut √™tre am√©lior√©e par ML)
  raw_category TEXT, -- Cat√©gorie de la source
  raw_tags TEXT[], -- Tags de la source
  
  -- Statut de traitement
  status TEXT DEFAULT 'pending', -- 'pending', 'processing', 'processed', 'error'
  processing_error TEXT,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index pour performance
CREATE INDEX idx_events_published_at ON events(published_at DESC);
CREATE INDEX idx_events_status ON events(status);
CREATE INDEX idx_events_source ON events(source);
```

---

## üîÑ Couche 2 : Traitement & Analyse

### Pipeline de traitement

#### √âtape 1 : Normalisation
```typescript
// src/server/processors/normalizer.ts
interface RawEvent {
  source: string;
  data: any;
}

interface NormalizedEvent {
  title: string;
  description: string;
  published_at: Date;
  source: string;
  source_id: string;
  url?: string;
}

function normalizeEvent(raw: RawEvent): NormalizedEvent {
  // Normaliser selon la source
  // - Formater les dates
  // - Nettoyer le texte
  // - Extraire les m√©tadonn√©es
}
```

#### √âtape 2 : Enrichissement
```typescript
// src/server/processors/enricher.ts
interface EnrichedEvent extends NormalizedEvent {
  // Entit√©s nomm√©es
  entities: {
    organizations: string[];
    locations: string[];
    people: string[];
    products: string[];
  };
  
  // Classification
  level: 'Geopolitical' | 'Industrial' | 'Supply Chain' | 'Market' | 'Regulatory';
  sectors: string[]; // ['Technology', 'Energy', 'Finance', etc.]
  regions: string[]; // ['US', 'EU', 'China', etc.]
  
  // Sentiment
  sentiment: 'positive' | 'negative' | 'neutral';
  sentiment_score: number; // -1 to 1
}
```

#### √âtape 3 : Analyse causale
```typescript
// src/server/analyzers/causal-analyzer.ts
interface CausalChain {
  event_id: UUID;
  direct_impacts: Impact[];
  second_order_impacts: Impact[];
  third_order_impacts: Impact[];
}

interface Impact {
  type: 'market' | 'supply_chain' | 'regulatory' | 'geopolitical';
  sector: string;
  region: string;
  asset_class?: string; // 'equity', 'commodity', 'currency', etc.
  timeframe: string; // 'immediate', '1-7d', '1-4w', '1-3m', '6m+'
  confidence: number; // 0-1
  description: string;
}
```

#### √âtape 4 : Pr√©dictions
```typescript
// src/server/analyzers/predictor.ts
interface Prediction {
  event_id: UUID;
  asset: string; // 'Crude Oil', 'Semiconductor ETF', etc.
  direction: 'up' | 'down' | 'neutral';
  magnitude: number; // Pourcentage estim√©
  confidence: number; // 0-1
  timeframe: string; // '12-24h', '24-48h', etc.
  reasoning: string; // Explication causale
}
```

### Tables Supabase pour le traitement

```sql
-- Table: processed_events (√©v√©nements trait√©s)
CREATE TABLE processed_events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  event_id UUID REFERENCES events(id) ON DELETE CASCADE,
  
  -- Classification
  level TEXT NOT NULL CHECK (level IN ('Geopolitical', 'Industrial', 'Supply Chain', 'Market', 'Regulatory')),
  sectors TEXT[] NOT NULL,
  regions TEXT[] NOT NULL,
  
  -- Entit√©s
  entities JSONB, -- {organizations: [], locations: [], people: []}
  
  -- Sentiment
  sentiment TEXT CHECK (sentiment IN ('positive', 'negative', 'neutral')),
  sentiment_score NUMERIC, -- -1 to 1
  
  -- M√©tadonn√©es de traitement
  processed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  processing_version TEXT, -- Version du mod√®le utilis√©
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table: causal_chains (cha√Ænes causales)
CREATE TABLE causal_chains (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  event_id UUID REFERENCES processed_events(id) ON DELETE CASCADE,
  
  -- Impacts directs
  direct_impacts JSONB NOT NULL, -- Array of Impact objects
  
  -- Impacts de second ordre
  second_order_impacts JSONB,
  
  -- Impacts de troisi√®me ordre
  third_order_impacts JSONB,
  
  -- M√©tadonn√©es
  generated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  model_version TEXT,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table: predictions (pr√©dictions de march√©)
CREATE TABLE predictions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  event_id UUID REFERENCES processed_events(id) ON DELETE CASCADE,
  causal_chain_id UUID REFERENCES causal_chains(id),
  
  asset TEXT NOT NULL, -- 'Crude Oil (WTI)', 'Semiconductor ETF', etc.
  asset_type TEXT, -- 'commodity', 'equity', 'currency', 'index'
  direction TEXT NOT NULL CHECK (direction IN ('up', 'down', 'neutral')),
  magnitude NUMERIC, -- Pourcentage estim√©
  confidence NUMERIC NOT NULL CHECK (confidence >= 0 AND confidence <= 1),
  timeframe TEXT NOT NULL, -- '12-24h', '24-48h', '48-72h', etc.
  reasoning TEXT NOT NULL,
  
  -- Statut
  status TEXT DEFAULT 'active', -- 'active', 'fulfilled', 'expired', 'invalidated'
  actual_outcome TEXT, -- Rempli apr√®s v√©rification
  accuracy_score NUMERIC, -- Calcul√© apr√®s v√©rification
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  expires_at TIMESTAMP WITH TIME ZONE
);
```

---

## üéØ Couche 3 : Recommandations & Distribution

### Syst√®me de matching utilisateur

#### Profil utilisateur (d√©j√† dans `users` table)
```typescript
interface UserProfile {
  id: string;
  sector: string; // 'Technology', 'Energy', 'Finance', etc.
  professional_role: string; // 'analyst', 'trader', 'portfolio_manager', etc.
  intended_use: string; // Usage d√©clar√©
  exposure: string; // 'retail', 'institutional', 'enterprise', etc.
  company?: string;
}
```

#### Algorithme de scoring

```typescript
// src/server/recommendations/scorer.ts
interface RecommendationScore {
  event_id: UUID;
  user_id: UUID;
  score: number; // 0-100
  reasons: string[];
}

function calculateRelevanceScore(
  event: ProcessedEvent,
  user: UserProfile
): RecommendationScore {
  let score = 0;
  const reasons: string[] = [];
  
  // 1. Match par secteur (40 points max)
  if (event.sectors.includes(user.sector)) {
    score += 40;
    reasons.push(`Relevant to your sector: ${user.sector}`);
  }
  
  // 2. Match par r√¥le professionnel (30 points max)
  const roleWeights = {
    'analyst': ['Geopolitical', 'Industrial', 'Regulatory'],
    'trader': ['Market', 'Supply Chain'],
    'portfolio_manager': ['Market', 'Geopolitical', 'Industrial'],
    'researcher': ['Geopolitical', 'Regulatory', 'Industrial'],
  };
  
  if (roleWeights[user.professional_role]?.includes(event.level)) {
    score += 30;
    reasons.push(`Matches your role: ${user.professional_role}`);
  }
  
  // 3. Match par intended_use (20 points max)
  // Analyse du texte pour trouver des mots-cl√©s pertinents
  if (matchesIntendedUse(event, user.intended_use)) {
    score += 20;
    reasons.push(`Aligned with your use case`);
  }
  
  // 4. Match par exposure (10 points max)
  // Les √©v√©nements critiques sont plus importants pour les institutions
  if (user.exposure === 'institutional' && event.level === 'Critical') {
    score += 10;
    reasons.push(`Critical event for institutional exposure`);
  }
  
  return { event_id: event.id, user_id: user.id, score, reasons };
}
```

### Table de recommandations

```sql
-- Table: user_recommendations (recommandations personnalis√©es)
CREATE TABLE user_recommendations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  event_id UUID REFERENCES processed_events(id) ON DELETE CASCADE,
  prediction_id UUID REFERENCES predictions(id),
  
  -- Scoring
  relevance_score NUMERIC NOT NULL CHECK (relevance_score >= 0 AND relevance_score <= 100),
  reasons TEXT[] NOT NULL,
  
  -- Statut
  status TEXT DEFAULT 'new', -- 'new', 'viewed', 'dismissed', 'saved'
  viewed_at TIMESTAMP WITH TIME ZONE,
  dismissed_at TIMESTAMP WITH TIME ZONE,
  
  -- Priorit√©
  priority TEXT DEFAULT 'normal', -- 'low', 'normal', 'high', 'critical'
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index pour performance
CREATE INDEX idx_user_recommendations_user_id ON user_recommendations(user_id);
CREATE INDEX idx_user_recommendations_score ON user_recommendations(relevance_score DESC);
CREATE INDEX idx_user_recommendations_status ON user_recommendations(status);
CREATE INDEX idx_user_recommendations_priority ON user_recommendations(priority);
```

### Fonction Supabase pour g√©n√©rer les recommandations

```sql
-- Fonction pour g√©n√©rer les recommandations pour un utilisateur
CREATE OR REPLACE FUNCTION generate_user_recommendations(
  p_user_id UUID,
  p_limit INTEGER DEFAULT 50
)
RETURNS TABLE (
  recommendation_id UUID,
  event_id UUID,
  title TEXT,
  level TEXT,
  relevance_score NUMERIC,
  reasons TEXT[]
) AS $$
BEGIN
  RETURN QUERY
  WITH user_profile AS (
    SELECT sector, professional_role, intended_use, exposure
    FROM users
    WHERE id = p_user_id
  ),
  scored_events AS (
    SELECT 
      pe.id as event_id,
      pe.level,
      e.title,
      -- Calcul du score de pertinence (simplifi√©)
      CASE 
        WHEN pe.sectors @> ARRAY[up.sector] THEN 40
        ELSE 0
      END +
      CASE 
        WHEN up.professional_role = 'analyst' AND pe.level IN ('Geopolitical', 'Industrial', 'Regulatory') THEN 30
        WHEN up.professional_role = 'trader' AND pe.level IN ('Market', 'Supply Chain') THEN 30
        WHEN up.professional_role = 'portfolio_manager' AND pe.level IN ('Market', 'Geopolitical', 'Industrial') THEN 30
        ELSE 0
      END +
      CASE 
        WHEN up.exposure = 'institutional' AND pe.level = 'Critical' THEN 10
        ELSE 0
      END as relevance_score,
      ARRAY[
        CASE WHEN pe.sectors @> ARRAY[up.sector] THEN 'Relevant to your sector' END,
        CASE WHEN up.professional_role = 'analyst' AND pe.level IN ('Geopolitical', 'Industrial', 'Regulatory') 
          THEN 'Matches your analytical role' END
      ]::TEXT[] as reasons
    FROM processed_events pe
    CROSS JOIN user_profile up
    JOIN events e ON e.id = pe.event_id
    WHERE pe.processed_at > NOW() - INTERVAL '7 days' -- Derniers 7 jours
    AND NOT EXISTS (
      SELECT 1 FROM user_recommendations ur
      WHERE ur.user_id = p_user_id AND ur.event_id = pe.id
    )
  )
  SELECT 
    gen_random_uuid() as recommendation_id,
    se.event_id,
    se.title,
    se.level,
    se.relevance_score,
    se.reasons
  FROM scored_events se
  WHERE se.relevance_score > 30 -- Seuil minimum
  ORDER BY se.relevance_score DESC
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

---

## üîß Technologies Recommand√©es

### Backend (Pipeline)

#### Option 1 : **Node.js + TypeScript** (recommand√© pour commencer)
```typescript
// Avantages
- M√™me langage que le frontend
- √âcosyst√®me riche (libraries NLP, APIs)
- Facile √† d√©ployer (Vercel, Railway, etc.)
- Int√©gration facile avec Supabase
```

#### Option 2 : **Python** (pour ML/AI avanc√©)
```python
# Avantages
- Meilleur √©cosyst√®me ML (spaCy, transformers, etc.)
- Biblioth√®ques NLP puissantes
- Facile √† int√©grer avec Supabase (via REST API)
```

### Services

1. **Supabase** : Base de donn√©es + Auth + Realtime
2. **Vercel/Netlify** : D√©ploiement frontend
3. **Railway/Render** : D√©ploiement workers/background jobs
4. **OpenAI API** : Pour l'analyse de texte et g√©n√©ration de pr√©dictions
5. **Anthropic Claude** : Alternative pour l'analyse

---

## üöÄ Plan d'Impl√©mentation (MVP)

### Phase 1 : Infrastructure de base (Semaine 1-2)
- [ ] Cr√©er les tables Supabase (`events`, `processed_events`, `predictions`)
- [ ] Cr√©er un worker Node.js pour la collecte de donn√©es
- [ ] Int√©grer NewsAPI pour commencer
- [ ] Pipeline de normalisation basique

### Phase 2 : Traitement basique (Semaine 3-4)
- [ ] Enrichissement avec entit√©s nomm√©es (spaCy ou OpenAI)
- [ ] Classification par niveau (Geopolitical, Industrial, etc.)
- [ ] Extraction de secteurs et r√©gions
- [ ] Stockage dans `processed_events`

### Phase 3 : Recommandations (Semaine 5-6)
- [ ] Fonction Supabase `generate_user_recommendations`
- [ ] Algorithme de scoring basique
- [ ] API endpoint pour r√©cup√©rer les recommandations
- [ ] Affichage dans le dashboard

### Phase 4 : Pr√©dictions (Semaine 7-8)
- [ ] Analyse causale basique (r√®gles + LLM)
- [ ] G√©n√©ration de pr√©dictions
- [ ] Stockage dans `predictions`
- [ ] Affichage dans le dashboard

### Phase 5 : Am√©lioration continue
- [ ] ML pour am√©liorer le scoring
- [ ] Feedback utilisateur pour am√©liorer les recommandations
- [ ] A/B testing des algorithmes
- [ ] M√©triques et analytics

---

## üìù Exemple de Code - Worker de Collecte

```typescript
// src/server/workers/data-collector.ts
import { createClient } from '@supabase/supabase-js';
import NewsAPI from 'newsapi';

const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const newsapi = new NewsAPI(process.env.NEWS_API_KEY!);

async function collectNewsEvents() {
  try {
    // R√©cup√©rer les derni√®res actualit√©s
    const response = await newsapi.v2.topHeadlines({
      category: 'business',
      language: 'en',
      pageSize: 100,
    });

    for (const article of response.articles) {
      // V√©rifier si l'√©v√©nement existe d√©j√†
      const { data: existing } = await supabase
        .from('events')
        .select('id')
        .eq('source', 'newsapi')
        .eq('source_id', article.url)
        .maybeSingle();

      if (!existing) {
        // Ins√©rer le nouvel √©v√©nement
        await supabase.from('events').insert({
          source: 'newsapi',
          source_id: article.url,
          title: article.title,
          description: article.description,
          content: article.content,
          published_at: article.publishedAt,
          url: article.url,
          author: article.author,
          status: 'pending',
        });
      }
    }
  } catch (error) {
    console.error('Error collecting news:', error);
  }
}

// Ex√©cuter toutes les heures
setInterval(collectNewsEvents, 60 * 60 * 1000);
collectNewsEvents(); // Ex√©cuter imm√©diatement
```

---

## üéØ Prochaines √âtapes

1. **Cr√©er les tables Supabase** pour les √©v√©nements et recommandations
2. **D√©velopper un worker de collecte** simple (NewsAPI pour commencer)
3. **Cr√©er une API endpoint** pour r√©cup√©rer les recommandations utilisateur
4. **Int√©grer dans le dashboard** pour afficher les recommandations personnalis√©es

Souhaitez-vous que je commence par cr√©er les tables Supabase et un worker de collecte basique ?

